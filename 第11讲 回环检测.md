# 第11讲 回环检测

## 11.1 概述

### 11.1.1 回环检测的意义

在SLAM系统中，前端提供特征点的提取、相机轨迹和地图的初值，后端负责对所有这些数据进行优化。然而，如果像VO那样仅考虑相邻时间上的关键帧，那么，之前产生的误差将不可避免地累积到下一个时刻，使得整个SLAM出现累计误差，长期估计的结果将不可靠，即我们无法构建全局一致的地图和轨迹。

回环检测对于SLAM系统意义重大。一方面，它关系到我们估计的轨迹和地图在长时间下的正确性。另一方面，由于回环检测提供了当前数据与所有历史数据的关联，我们还可以利用回环检测进行重定位。例如，如果我们事先对某个场景录制了一条轨迹并建立了地图，那么之后在该场景中就可以一直跟随这条轨迹进行导航，而重定位可以帮助我们确定自身在这条轨迹上的位置。

因此，回环检测对整个SLAM系统与稳健性的提升是非常明显的。甚至在某些时候，把仅有前端和局部后端的系统成为视觉里程计（VO），而把带有回环检测和全局后端的系统称为SLAM。

### 11.1.2 回环检测的方法

回环检测的实现有多种思路，包括理论上的和工程上的。

其中一种最简单的思路就是，对任意两幅图像都做一遍特征匹配，但需要检测的数量太大，效率太低，不实用。另一种思路是在历史数据中随机抽取一些帧与当前帧进行比较，但是这种做法随机性太大，也不实用。（虽然随即检测在有些实现中确实有效）

上述的朴素思路都过于粗糙，因此，我们希望有一个“**哪处可能出现回环**”的预计，不那么盲目地去检测。大体有两种思路：

一是基于里程计（Odometry based）的几何关系，即当我们“发现当前相机运动到了之前的某个位置附近”时，检测它们有没有回环关系。但要澄清的是，“发现当前相机运动到了之前的某个位置附近”是回环检测的目的，而不是前提，故这种方法有倒果为因的嫌疑，在累计误差较大时是无法工作的。

二是基于外观（Appearance based）的几何关系，它与前端、后端的估计都无关，仅根据两幅图像的相似性确定回环检测关系。这种做法摆脱了累计误差，使回环检测成为SLAM系统中一个相对独立的模块，是视觉SLAM中的主流方法，实用性强。

除此之外，从工程角度也能提出一些解决回环检测的方法。例如，室外无人车通常会配备GPS，提供全局位置信息。利用GPS信息可以很轻松地判断汽车是否回到某个经过的位置，但这种方法在室内就不好用了。

在基于外观的回环检测算法中，核心问题是**如何计算图像间的相似性**。即对于图像$\boldsymbol{A}$和图像$\boldsymbol{B}$，要设计一种方法，计算它们之间的相似性评分：$s(\boldsymbol{A}, \boldsymbol{B})$，当这个评分超过一定的阈值时，认为出现了一个回环。

一种计算相似性评分的朴素方法是将两幅图像相减，并取某种范数：
$$
s(\boldsymbol{A}, \boldsymbol{B}) = \| \boldsymbol{A} - \boldsymbol{B}\|
$$
在图像处理课程中已经学过，由于环境光照等影响，即使它们很相似，这样计算出来的差异也可能很大，不能很好地反应图像间的相似关系。如果要评估一个能计算图像相似性的模型好不好，要先引入准确率和召回率的概念。

### 11.1.3 准确率和召回率

这一部分和机器学习中学习到的基本是一致的。

准确率和召回率通常是矛盾的，在SLAM中，我们对准确率的要求要比召回率高，因为错误的回环会导致很严重的后果。相比之下，召回率低一些，顶多有些回环没有检测到，地图会多受一些累计误差的影响，并且仅需一两次回环就可以消除它们了。所以，在选择回环检测算法时，我们更倾向于把参数设置得更严格，或者在检测之后再加上**回环验证**的步骤。

回到之前说的$s(\boldsymbol{A}, \boldsymbol{B}) = \| \boldsymbol{A} - \boldsymbol{B}\|$，它之所以不好的原因就是准确率和召回率都很差。

## 11.2 词袋模型

词袋模型是一种可靠的计算图像相似性的方法。词袋（Bag-of-Words，BoW）用“图像上有哪几种特征”来描述一幅图像。根据对图像的描述，可以度量两幅图像的相似性，具体可分为以下3步：

1. 确定“特征”的概念 ，即BoW中的“单词”（Word），许多单词放在一起，组成了“字典”（Dictionary）
2. 确定图像中出现了哪些在字典中定义的概念，具体来说，是根据图像中单词出现的情况，用向量来描述它
3. 利用描述图像的向量来计算相似程度

例如，“人”“车”“狗”都是记录在字典中的单词，记为$w_1, w_2, w_3$。假设图像$\boldsymbol{A}$中有一个人和一辆车，则可记为：
$$
\boldsymbol{A} = 1 \cdot w_1 + 1 \cdot w_2 + 0 \cdot w_3
$$
即，可以用向量$\boldsymbol{a} = [1, 1, 0]^\top$来描述图像$\boldsymbol{A}$。

注意：描述向量强调的是单词“**是否出现**”，并不管它们“**在哪里出现**”，所以与物体的空间描述和排列顺序无关。当相机发生少量运动时，只要物体仍在视野中，描述向量就不会发生变化。

假设图像$\boldsymbol{B}$可以用向量$\boldsymbol{b} = [1, 0, 1]^\top$来描述，则根据向量$\boldsymbol{a}, \boldsymbol{b} \in \mathbb{R}^W$，设计一定的计算方式，就能确定图像间的相似性，例如：
$$
s(\boldsymbol{A}, \boldsymbol{B}) = 1 - \frac{1}{W} \| \boldsymbol{a} - \boldsymbol{b} \|_1
$$
当两个向量完全一样时，相似度为1，当完全相反时，相似度为0。

现在的问题是：

1. 字典是怎么来的？
2. 如果能够计算两幅图像的相似性评分，是否足够判断回环？

下面，学习字典的生成方式，以及如何利用字典实际计算两幅图像的相似性。

## 11.3 字典

### 11.3.1 字典的结构

字典的生成问题类似于一个聚类（Clustering）问题。首先，假设我们对大量的图像提取了$N$个特征点，利用K-means聚类，可以将其归为$k$个类（K-means的原理参见机器学习相关资料）。现在的问题就变成了：如何根据图像中某个特征点，查找字典中相应的单词。

朴素的思想是，计算特征点和这$k$个类的中心的距离，将其归为最近的那个类。但是，实用字典的规模通常很大，可能有上百万个单词，如果这样一一比对的话，效率太低了。因此，在实践中会用更复杂的数据结构来表示字典以提高搜索效率。这里介绍一种简单且实用的树结构：$k$叉树。

$k$叉树的原理很简单，类似于层次聚类。假定我们在根节点有$N$个样本（特征点），希望构建一个深度为$d$、每次分叉数为$k$的树，步骤如下：

1. 在根节点，用K-means把所有样本聚成$k$类，得到第一层
2. 对第一层的每个节点，把属于该节点的样本再聚成$k$类，得到下一层
3. 以此类推，得到叶子层（第$d$层），每个叶子节点都是一个Word

实际上，这样构建出来的字典中的单词是一个个的叶子节点，而树结构起到快速查找的作用。这样，一个深度为$d$、每次分叉数为$k$的字典树可以容纳$k^d$个单词，每次查询只需要计算$kd$次，效率从$O(k^d)$变为$O(kd)$。

### 11.3.2 实践：创建字典

具体见代码。

## 11.4 相似度计算

### 11.4.1 理论部分

有了字典之后，给定任意特征$f_i$，只要在字典树中逐层查找，最后都能找到与之对应的单词$w_j$，当字典足够大时，我们可以认为$f_i$与$w_j$来自同一类物体。那么，假设从一幅图像中提取了$N$个特征，找到这$N$个特征对应的单词之后，就相当于拥有了该图像在单词列表中的分布，即Bag。

但是，我们希望对单词的重要性加以评估，给它们不同的权值，使其更有区分度。TF-IDF（Term Frequency-Inverse Document Frequency）是文本检索中常用的一种加权方式，也用于BoW模型中。TF部分的思想是：某单词在一幅图像中经常出现，它的区分度就越高。IDF的思想是：某单词在字典中出现的频率越低，分类图像时区分度越高。

我们可以在建立字典时计算IDF：统计某个叶子节点$w_i$中特征数量与根节点中特征数量的比例。假设根节点特征数量为$n$，$w_i$特征数量为$n_i$，那么，该单词的IDF为：
$$
\mathrm{IDF}_i = \log \frac{n}{n_i}
$$
TF部分则是指某个特征在单幅图像中出现的频率。假设图像$\boldsymbol{A}$中单词$w_i$出现了$n_i$次，而一共出现的单词次数为$n$，那么TF为：
$$
\mathrm{TF}_i = \frac{n_i}{n}
$$
于是，$w_i$的权重等于TF与IDF的积：
$$
\eta_i = \mathrm{TF}_i \times \mathrm{IDF}_i
$$
考虑权重以后，对于某幅图像$\boldsymbol{A}$，它的特征点可对应到许多个单词，组成它的BoW：
$$
\boldsymbol{v}_A \overset{\mathrm{def}}{=} \{(w_1, \eta_1), (w_2, \eta_2), \dots, (w_N, \eta_N)\}
$$
由于相似的特征可能落到同一个类（单词）中，因此实际的$\boldsymbol{v}_A$会存在大量的零，即它是一个稀疏的向量，其非零部分指示了图像$\boldsymbol{A}$中有哪些单词，这些部分的值为TF-IDF。

现在，给定$\boldsymbol{v}_A, \boldsymbol{v}_B$，就可以计算图像$\boldsymbol{A}, \boldsymbol{B}$的差异了，具体的计算方式有很多种，例如：
$$
s(\boldsymbol{A}, \boldsymbol{B}) = 2 \sum_{i = 1}^{N} |\boldsymbol{v}_{Ai}| + |\boldsymbol{v}_{Bi}| - |\boldsymbol{v}_{Ai} - \boldsymbol{v}_{Bi}| 
$$

### 11.4.2 实践：相似度的计算

具体见代码。

## 11.5 实验分析与评述

### 11.5.1 增加字典规模

增加字典规模时，无关图像的相似性明显变小，而相似的图像，虽然分值也略微下降，但是相对来说有了更大的区分度，这说明增加字典训练样本是有益的。

### 11.5.2 相似性评分的处理

对任意两幅图像，我们都能给出一个相似性评分，但是只利用这个分值的绝对大小不一定有很好的帮助。例如，有些环境的外观本来就很相似，另一些环境则各个地方都有很大的不同。考虑到这种情况，我们会取一个**先验相似度**$s(\boldsymbol{v}_t, \boldsymbol{v}_{t - \Delta t})$，它表示某时刻关键帧图像与上一时刻的关键帧图像的相似性，然后其他的分值都参照这个值进行归一化：
$$
s(\boldsymbol{v}_t, \boldsymbol{v}_{tj})' = s(\boldsymbol{v}_t, \boldsymbol{v}_{tj}) / s(\boldsymbol{v}_t, \boldsymbol{v}_{t - \Delta t}) 
$$
站在这个角度上，我们说：如果当前帧与之前某关键帧的相似度超过当前帧与上一个关键帧相似度的3倍，就认为可能存在回环。这个步骤避免了引入绝对的相似性阈值，使得算法能够适应更多的环境。

### 11.5.3 关键帧的处理

在检测回环时，必须考虑到关键帧的选取。如果关键帧选得太近，那么将导致两个关键帧之间的相似性过高，相比之下不容易检测出历史数据中的回环。从实践上说，用于回环检测的帧最好稀疏一些，彼此之间不太相同，又能覆盖整个环境。

另外，如果成功检测到了回环，例如，第$1$帧和第$n$帧出现了回环，对轨迹进行了优化，消除了累计误差。但是，第$n + 1$帧、第$n + 2$帧很可能也都和第$1$帧构成回环，这产生的帮助就没那么大了。所以，我们会把“相近”的回环聚为一类，使算法不要反复地检测同一类的回环。

### 11.5.4 检测之后的验证

词袋的回环检测算法完全依赖于外观而没有利用任何的几何信息，这导致外观相似的图像容易被当成回环。并且，由于词袋不在乎单词顺序，只在乎有无的表达，容易引发错误。所以，在回环检测之后，通常还有一个验证步骤。

验证的方法有很多。一个方法是设立回环的缓存机制，认为单次检测到的回环并不足以构成良好的约束，而在一段时间中一直检测到的回环，才是正确的回环。这可以看成时间上的一致性检测。另一个方法是空间上的一致性检测，即对回环检测到的两个帧进行特征匹配，估计相机的运动。然后，把运动放到之前的位姿图中，检查与之前的估计是否有很大的出入。总之，验证部分通常是必须的，但实现方法上有很多。

### 11.5.5 与机器学习的关系

回环检测本身非常像是一个聚类问题，可以把特征点“聚”到某一个单词下。回环中的类别数量很大，而每类的样本很少，在极端情况下，当机器人发生运动后，图像发生变化，就产生了新的类别。甚至，可以把类别当成连续变量而非离散变量。

从另一个角度来看，回环检测相当于对“图像间相似性”概念的一个学习。既然人类能够判断图像是否相似，让机器学习到这样的概念也是非常有可能的。

词袋模型本身是一个非监督机器学习的过程，构建词典相当于对特征描述子进行聚类，而$k$叉树只是对所聚的类的一个提供快速查找的数据结构。结合机器学习中的知识，可以思考两个问题：

1. 是否能对机器学习的图像特征进行聚类，而不是人工设计特征（如ORB）进行聚类？
2. 是否有比K-means加树结构更好的聚类算法？

结合目前机器学习的发展来看，答案是肯定的。目前，已经有很多基于深度学习的回环检测算法，也有网络能直接根据两张图像计算相机的位姿变化。尽管目前词袋方法仍是主流，但是在未来，深度学习方法会有更大的表现舞台，成为新的主流。