# 第2讲 初识SLAM

## 2.1 经典视觉SLAM框架

整个视觉SLAM流程包括以下几个步骤：

1. **传感器数据获取**：在视觉SLAM中，主要为相机图像信息的读取和预处理

2. **前端视觉里程计**（Visual Odometry，VO）：估算相邻图像间相机的运动，以及局部地图的样子

   前端里程计是SLAM的关键：

   一方面，将相邻时刻的运动“串”起来，就构成了机器人的运动轨迹，从而解决**定位**问题。

   另一方面，根据每个时刻相机的位置，计算各像素点对应空间点的位置，就得到了**地图**。

   但是，仅通过里程计来估计轨迹，将不可避免地出现**漂移问题**，即累计误差。因此，还需要**后端优化**和**回环检测**：回环检测负责把“机器人回到原始位置”这件事检测出来，而后端优化则根据该信息对轨迹进行矫正。

3. **后端（非线性）优化**（Optimization）：后端接受不同时刻视觉里程计测量的相机位姿和回环检测的信息，对它们进行优化，得到全局一致的轨迹和地图

   后端负责整体的优化过程，它往往面对的只有数据，而不必关心这些数据到底来自什么传感器。主要与滤波与非线性优化算法有关。

4. **回环检测**（Loop Closure Detection）：判断机器人是否达到过先前的位置。如果检测到回环，把信息提供给后端进行处理

   我们需要让机器人具有识别到过的场景的能力，也就是保证机器人在**不同时刻，同一位置**的估计值一致，从而消除累计误差。将诸如“A和B是同一个点”这样的信息传递给后端，使后端把轨迹和地图调整到符合回环检测结果的样子，得到全局一致的轨迹和地图。

   例如，在视觉SLAM中，可以判断图像间的**相似性**来完成回环检测，这个很容易用深度学习算法完成。

5. **建图**（Mapping）：根据估计的轨迹，建立与任务要求对应的地图

   地图是对环境的描述，不同的应用场景有**不同的描述方式**，例如：2D栅格地图、3D点云地图

   地图没有固定的形式和算法，一组空间点的集合和一个漂亮的3D模型都可以称为地图。大体可以分为**度量地图**和**拓扑地图**。

   度量地图：用稀疏和稠密分类，稀疏地图由一组路标组成，可以用于定位。而稠密地图着重建模所有物体，需要按照某种分辨率把场景分为很多个小单元，标记每个小单元的状态（占据、空闲、未知），可用于各种导航算法，但会耗费大量存储空间，有时会出现一致性问题。

   拓扑地图：用节点和边构图，强调地图元素之间的关系，如连通性。

![image-20241016112000085](C:\Users\48423\AppData\Roaming\Typora\typora-user-images\image-20241016112000085.png)

## 2.2 SLAM问题的数学表述

相机通常是在某些时刻采集数据的，我们只关心这些时刻（$t = 1, \cdots, K$）的位置和地图。在这些时刻，用$\boldsymbol{x}_1, \cdots, \boldsymbol{x}_K$表示机器人的位姿，他们构成了轨迹。地图方面，假设地图是由$\boldsymbol{y}_1, \cdots, \boldsymbol{y}_N$这$N$个路标组成的，每个时刻传感器会测量到一部分路标点，得到它们对应的观测数据。

**运动方程：**考察从$k-1$时刻$k$时刻，机器人位姿$\boldsymbol{x}$的变化情况
$$
\boldsymbol{x}_k = f(\boldsymbol{x}_{k - 1}, \boldsymbol{u}_k, \boldsymbol{w}_k)
$$
其中，$\boldsymbol{u}_k$为机器人携带的**测量自身运动**的传感器的读数，$\boldsymbol{w}_k$为噪声

**观测方程：**描述机器人在$k$时刻观察到了某一个路标$\boldsymbol{y}_j$的情况（某个时刻若观察到多个路标，则有由多个观测方程组成的方程组）
$$
\boldsymbol{z}_{k,j} = h(\boldsymbol{y}_j,\boldsymbol{x}_k,\boldsymbol{v}_{k, j})
$$
其中，$\boldsymbol{z}_{k, j}$为观测数据，$\boldsymbol{y}_j$为路标点，$\boldsymbol{v}_{k,j}$为噪声

总而言之，定位问题即为估计$\boldsymbol{x}$，建图问题即为估计$\boldsymbol{y}$，SLAM问题根据这两个基本方程建模为状态估计问题，而方程的具体形式，取决于我们如何对方程中的变量进行**参数化**。
